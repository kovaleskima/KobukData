{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87aa486e",
   "metadata": {},
   "source": [
    "## Recycled code for bearings processing\n",
    "- Need to make this into its own separate script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a147e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import ast\n",
    "import os, re\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a24f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"./consolidated cracks/*.txt\"\n",
    "rows = []\n",
    "\n",
    "DATE_RE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1f07a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        date    crack        lat         lon\n",
      "0  2014  2014-05-19  Crack 1  67.010664 -162.132102\n",
      "1  2014  2014-05-19  Crack 1  67.008640 -162.129449\n",
      "2  2014  2014-05-19  Crack 1  67.006616 -162.126797\n",
      "3  2014  2014-05-19  Crack 1  67.004592 -162.124146\n",
      "4  2014  2014-05-19  Crack 1  67.001028 -162.129183\n",
      "Total rows: 4248\n"
     ]
    }
   ],
   "source": [
    "for filepath in sorted(glob.glob(pattern)):\n",
    "    filename = os.path.basename(filepath)\n",
    "    date_str = filename.replace(\".txt\", \"\")\n",
    "    year = date_str.split(\"-\")[0]\n",
    "\n",
    "    # Read file\n",
    "    with open(filepath, \"r\") as f:\n",
    "        file_content = f.read().strip()\n",
    "\n",
    "    # Parse safely\n",
    "    try:\n",
    "        cracks_dict = ast.literal_eval(file_content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Flatten cracks into rows\n",
    "    for crack_name, coords_list in cracks_dict.items():\n",
    "        for lat, lon in coords_list:\n",
    "            rows.append([year, date_str, crack_name, lat, lon])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows, columns=[\"year\", \"date\", \"crack\", \"lat\", \"lon\"])\n",
    "\n",
    "print(df.head())\n",
    "print(f\"Total rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9214a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def segment_bearing_deg(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Initial great-circle bearing from (lat1,lon1) to (lat2,lon2), in [0,360).\"\"\"\n",
    "    φ1, φ2 = math.radians(lat1), math.radians(lat2)\n",
    "    Δλ = math.radians(lon2 - lon1)\n",
    "    x = math.sin(Δλ) * math.cos(φ2)\n",
    "    y = math.cos(φ1) * math.sin(φ2) - math.sin(φ1) * math.cos(φ2) * math.cos(Δλ)\n",
    "    θ = math.degrees(math.atan2(x, y))\n",
    "    return (θ + 360.0) % 360.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a5a3fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72.59821996173409, 72.59266607840902, 72.58711253022693, 72.5815593193741, 72.5760064456195, 72.57045390820204, 72.56490170783076, 72.55934984418167, 72.5537983179301, 72.5482471285004, 72.54269627624018]\n"
     ]
    }
   ],
   "source": [
    "from geopy import distance\n",
    "\n",
    "grouped = df.groupby([\"date\", \"crack\"])\n",
    "rows = []\n",
    "\n",
    "for (date, crack), group in grouped:\n",
    "    lats = group[\"lat\"].tolist()\n",
    "    lons = group[\"lon\"].tolist()\n",
    "\n",
    "    length = 0\n",
    "    segment_lengths = []\n",
    "    segment_bearings = []\n",
    "    bearings = []\n",
    "\n",
    "    for i in range(1, len(lats)):\n",
    "        p1 = (lats[i-1], lons[i-1])\n",
    "        p2 = (lats[i], lons[i])\n",
    "        length += abs(distance.distance(p1,p2).km)\n",
    "        segment_lengths.append(abs(distance.distance(p1,p2).km))\n",
    "        segment_bearings.append(segment_bearing_deg(p1[0], p1[1], p2[0], p2[1]))\n",
    "    # make axial\n",
    "    for b in segment_bearings:\n",
    "        b = b % 180\n",
    "        if b < 0: # if less than zero reflect into first two quadrants\n",
    "            b += 180\n",
    "        if b > 90: # if greater than 90 degrees find deviation from true north\n",
    "            b = 180 - b\n",
    "        bearings.append(b)\n",
    "    rows.append([date, crack, length, bearings])\n",
    "\n",
    "lo = pd.DataFrame(rows, columns=[\"date\", \"crack\", \"length\", \"bearings\"])\n",
    "print(bearings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd556dc",
   "metadata": {},
   "source": [
    "## Begin Winds Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69b08e59",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unrecognized engine cfgrib must be one of: ['scipy', 'store']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Open your three datasets\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m ds1 \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mera5_2023_2025_06.grib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcfgrib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m ds2 \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mera5_2014_2023_05.grib\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfgrib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m ds3 \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mera5_2014_05.grib\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfgrib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/subzero/lib/python3.9/site-packages/xarray/backends/api.py:574\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    572\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 574\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    577\u001b[0m     decode_cf,\n\u001b[1;32m    578\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    584\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    585\u001b[0m )\n\u001b[1;32m    587\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/subzero/lib/python3.9/site-packages/xarray/backends/plugins.py:205\u001b[0m, in \u001b[0;36mget_backend\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m    203\u001b[0m     engines \u001b[38;5;241m=\u001b[39m list_engines()\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m engines:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be one of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(engines)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m         )\n\u001b[1;32m    208\u001b[0m     backend \u001b[38;5;241m=\u001b[39m engines[engine]\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(engine, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(engine, BackendEntrypoint):\n",
      "\u001b[0;31mValueError\u001b[0m: unrecognized engine cfgrib must be one of: ['scipy', 'store']"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Open your three datasets\n",
    "ds1 = xr.open_dataset(\"era5_2023_2025_06.grib\", engine=\"cfgrib\")\n",
    "ds2 = xr.open_dataset(\"era5_2014_2023_05.grib\", engine=\"cfgrib\")\n",
    "ds3 = xr.open_dataset(\"era5_2014_05.grib\", engine=\"cfgrib\")\n",
    "\n",
    "# Concatenate along time dimension\n",
    "ds = xr.concat([ds1, ds2, ds3], dim=\"time\")\n",
    "\n",
    "# Make sure time is sorted (important if ranges overlap)\n",
    "ds = ds.sortby(\"time\")\n",
    "\n",
    "# Extract components\n",
    "u = ds[\"u10\"]\n",
    "v = ds[\"v10\"]\n",
    "\n",
    "# Latitude weights\n",
    "weights = np.cos(np.radians(ds[\"latitude\"]))\n",
    "weights.name = \"weights\"\n",
    "\n",
    "# Weighted spatial mean, then resample to daily mean\n",
    "u_daily = u.weighted(weights).mean(dim=(\"latitude\", \"longitude\")).resample(time=\"1D\").mean()\n",
    "v_daily = v.weighted(weights).mean(dim=(\"latitude\", \"longitude\")).resample(time=\"1D\").mean()\n",
    "\n",
    "# Convert to primary wind direction (degrees, meteorological convention)\n",
    "primary_dir = (180 + np.degrees(np.arctan2(u_daily, v_daily))) % 360\n",
    "\n",
    "# Put in dataframe\n",
    "primary_dir = primary_dir.to_dataframe(name=\"primary_wind_dir_deg\")\n",
    "\n",
    "print(primary_dir)\n",
    "#print(\"Number of daily values:\", len(primary_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d26196",
   "metadata": {},
   "source": [
    "## Show wind dir frequency histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(8, 6))\n",
    "colors = plt.cm.tab10.colors\n",
    "\n",
    "primary_dir = primary_dir.copy()\n",
    "primary_dir.index = pd.to_datetime(primary_dir.index)\n",
    "\n",
    "all_angles = []\n",
    "\n",
    "for date in primary_dir.index:\n",
    "    wind_angle_deg = primary_dir.loc[date, \"primary_wind_dir_deg\"]\n",
    "    if pd.isna(wind_angle_deg):\n",
    "        continue\n",
    "\n",
    "    wind_angle = np.radians(wind_angle_deg)\n",
    "\n",
    "    # ensure numeric\n",
    "    if np.isfinite(wind_angle):\n",
    "        all_angles.append(wind_angle)\n",
    "\n",
    "# convert list to numpy array\n",
    "all_angles = np.array(all_angles)\n",
    "print(\"Final array info:\", all_angles.shape, \"NaNs:\", np.isnan(all_angles).sum())\n",
    "\n",
    "# Define histogram parameters\n",
    "n_bins = 24  # 15 degrees per bin\n",
    "bins = np.linspace(0, 2*np.pi, n_bins + 1)\n",
    "\n",
    "counts, _ = np.histogram(all_angles, bins=bins)\n",
    "width = 2 * np.pi / n_bins\n",
    "\n",
    "bars = ax.bar(\n",
    "    bins[:-1], counts,\n",
    "    width=width,\n",
    "    align='edge',\n",
    "    color=colors[0],\n",
    "    edgecolor='k',\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Optional: color scale by frequency\n",
    "for bar, count in zip(bars, counts):\n",
    "    bar.set_facecolor(plt.cm.viridis(count / counts.max() if counts.max() > 0 else 0))\n",
    "\n",
    "# formatting\n",
    "ax.set_theta_zero_location(\"N\")\n",
    "ax.set_theta_direction(-1)\n",
    "ax.set_title(\"ERA5 Wind Direction Frequency by Day\", va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cce3a9",
   "metadata": {},
   "source": [
    "## Make KDE of diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_dir = primary_dir.copy()\n",
    "primary_dir.index = pd.to_datetime(primary_dir.index)\n",
    "\n",
    "all_diffs = []\n",
    "\n",
    "for date, group in lo.groupby(\"date\"):\n",
    "    # flatten bearings\n",
    "    bearings = np.concatenate(group[\"bearings\"].values)\n",
    "    bearings = bearings[np.isfinite(bearings)]\n",
    "    if len(bearings) == 0:\n",
    "        continue\n",
    "\n",
    "    bearings_rad = np.radians(bearings) # Convert to radians - all bearings <= 90 degrees\n",
    "\n",
    "    date_ts = pd.to_datetime(date)\n",
    "    if date_ts not in primary_dir.index:\n",
    "        continue\n",
    "\n",
    "    wind_angle_deg = primary_dir.loc[date_ts, \"primary_wind_dir_deg\"]\n",
    "    if pd.isna(wind_angle_deg):\n",
    "        continue\n",
    "    wind_angle = np.radians(wind_angle_deg) # Convert wind angle to radians\n",
    "\n",
    "    \n",
    "    # Wind can be blowing at most 180 degrees from the crack bearing (since cracks are axial ??)\n",
    "    diff = (bearings_rad - wind_angle) % np.pi\n",
    "\n",
    "    # Reflect differences greater than 90° to their acute complement\n",
    "    wind_diff = np.where(diff > np.pi / 2, np.pi - diff, diff)\n",
    "    wind_diff = wind_diff[np.isfinite(wind_diff)]\n",
    "    if len(wind_diff) == 0:\n",
    "        continue\n",
    "\n",
    "    wind_diff_axial = np.concatenate([wind_diff, wind_diff + np.pi])\n",
    "    wind_diff_axial = wind_diff_axial[np.isfinite(wind_diff_axial)]\n",
    "    if len(wind_diff_axial) > 0:\n",
    "        all_diffs.append(wind_diff_axial)\n",
    "\n",
    "# final concatenation\n",
    "all_diffs = np.concatenate(all_diffs)\n",
    "print(all_diffs)\n",
    "print(\"Final array info:\", all_diffs.shape, \"NaNs:\", np.isnan(all_diffs).sum())\n",
    "\n",
    "kde = gaussian_kde(all_diffs)\n",
    "theta = np.linspace(0, 2*np.pi, 180)\n",
    "density = kde(theta)\n",
    "\n",
    "ax.plot(theta, density, color=colors[i % len(colors)])\n",
    "\n",
    "ax.set_theta_zero_location(\"N\")\n",
    "ax.set_theta_direction(-1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subzero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
